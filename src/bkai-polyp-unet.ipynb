{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6938815,"sourceType":"datasetVersion","datasetId":3984786}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom torchvision.transforms import Resize, InterpolationMode, ToPILImage\nfrom pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import WandbLogger\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pytorch_lightning as pl\nimport torch\nimport cv2\nimport wandb\nimport argparse\nimport os\nimport random\n\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport albumentations as A","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-15T11:07:22.841407Z","iopub.execute_input":"2023-11-15T11:07:22.841798Z","iopub.status.idle":"2023-11-15T11:07:22.852590Z","shell.execute_reply.started":"2023-11-15T11:07:22.841766Z","shell.execute_reply":"2023-11-15T11:07:22.851361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NeoPolypDataset(Dataset):\n    def __init__(\n        self,\n        image_dir: list,\n        gt_dir: list | None = None,\n        session: str = \"train\"\n    ) -> None:\n        super().__init__()\n        self.session = session\n        if session == \"train\":\n            self.train_path = image_dir\n            self.train_gt_path = gt_dir\n            self.len = len(self.train_path)\n            self.train_transform = TrainTransform()\n        elif session == \"val\":\n            self.val_path = image_dir\n            self.val_gt_path = gt_dir\n            self.len = len(self.val_path)\n            self.val_transform = ValTransform()\n        else:\n            self.test_path = image_dir\n            self.len = len(self.test_path)\n            self.test_transform = TestTransform()\n            \n    @staticmethod\n    def _read_mask(mask_path):\n        image = cv2.imread(mask_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n        # lower boundary RED color range values; Hue (0 - 10)\n        lower1 = np.array([0, 100, 20])\n        upper1 = np.array([10, 255, 255])\n        # upper boundary RED color range values; Hue (160 - 180)\n        lower2 = np.array([160, 100, 20])\n        upper2 = np.array([179, 255, 255])\n        lower_mask = cv2.inRange(image, lower1, upper1)\n        upper_mask = cv2.inRange(image, lower2, upper2)\n\n        red_mask = lower_mask + upper_mask\n        red_mask[red_mask != 0] = 1\n\n        # boundary GREEN color range values; Hue (36 - 70)\n        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n        green_mask[green_mask != 0] = 2\n\n        full_mask = cv2.bitwise_or(red_mask, green_mask)\n        full_mask = full_mask.astype(np.uint8)\n        return full_mask\n\n    def __len__(self) -> int:\n        return self.len\n\n    def __getitem__(self, index: int):\n        if self.session == \"train\":\n            img = cv2.imread(self.train_path[index])\n            gt = self._read_mask(self.train_gt_path[index])\n            return self.train_transform(img, gt)\n        elif self.session == \"val\":\n            img = cv2.imread(self.val_path[index])\n            gt = self._read_mask(self.val_gt_path[index])\n            return self.val_transform(img, gt)\n        else:\n            img = cv2.imread(self.test_path[index])\n            H, W, _ = img.shape\n            img = self.test_transform(img)\n            file_id = self.test_path[index].split('/')[-1].split('.')[0]\n            return img, file_id, H, W","metadata":{"execution":{"iopub.status.busy":"2023-11-15T11:07:22.942442Z","iopub.execute_input":"2023-11-15T11:07:22.942809Z","iopub.status.idle":"2023-11-15T11:07:22.960438Z","shell.execute_reply.started":"2023-11-15T11:07:22.942782Z","shell.execute_reply":"2023-11-15T11:07:22.959343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainTransform:\n    def __init__(self) -> None:\n        self.transform = A.Compose([\n            A.HorizontalFlip(p=0.3),\n            A.VerticalFlip(p=0.3),\n            A.RandomGamma(gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n            A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n            A.OneOf([A.Blur(), A.GaussianBlur(), A.GlassBlur(), A.MotionBlur(),\n                    A.GaussNoise(), A.Sharpen(), A.MedianBlur(), A.MultiplicativeNoise()]),\n            A.CoarseDropout(p=0.2, max_height=35, max_width=35, fill_value=255),\n            A.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.15, brightness_coeff=1.5, p=0.09),\n            A.RandomShadow(p=0.1),\n            A.ShiftScaleRotate(p=0.45, border_mode=cv2.BORDER_CONSTANT, shift_limit=0.15, scale_limit=0.15),\n            A.Resize(256, 256, interpolation=cv2.INTER_LINEAR),\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n\n    def __call__(self, img, mask):\n        return self.transform(image=img, mask=mask)\n\n\nclass ValTransform:\n    def __init__(self) -> None:\n        self.transform = A.Compose([\n            A.Resize(256, 256, interpolation=cv2.INTER_LINEAR),\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n\n    def __call__(self, img, mask):\n        return self.transform(image=img, mask=mask)\n\n\nclass TestTransform:\n    def __init__(self) -> None:\n        self.transform = A.Compose([\n            A.Resize(256, 256, interpolation=cv2.INTER_LINEAR),\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n\n    def __call__(self, img):\n        return self.transform(image=img)['image']","metadata":{"execution":{"iopub.status.busy":"2023-11-15T11:07:22.962306Z","iopub.execute_input":"2023-11-15T11:07:22.962665Z","iopub.status.idle":"2023-11-15T11:07:22.989567Z","shell.execute_reply.started":"2023-11-15T11:07:22.962632Z","shell.execute_reply":"2023-11-15T11:07:22.988267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LOSS\n\n\ndef mask2rgb(mask):\n    color_dict = {0: torch.tensor([0, 0, 0]),\n                  1: torch.tensor([1, 0, 0]),\n                  2: torch.tensor([0, 1, 0])}\n    output = torch.zeros((mask.shape[0], mask.shape[1], mask.shape[2], 3)).long()\n    for i in range(mask.shape[0]):\n        for k in color_dict.keys():\n            output[i][mask[i].long() == k] = color_dict[k]\n    return output.to(mask.device)\n\n\n@torch.no_grad()\ndef dice_score(\n    inputs: torch.Tensor,\n    targets: torch.Tensor\n) -> torch.Tensor:\n    # compute softmax over the classes axis\n    input_one_hot = mask2rgb(inputs.argmax(dim=1))\n\n    # create the labels one hot tensor\n    target_one_hot = mask2rgb(targets)\n\n    # compute the actual dice score\n    dims = (2, 3)\n    intersection = torch.sum(input_one_hot * target_one_hot, dims)\n    cardinality = torch.sum(input_one_hot + target_one_hot, dims)\n\n    dice_score = (2. * intersection + 1e-6) / (cardinality + 1e-6)\n    return dice_score.mean()\n\n\nclass DiceLoss(nn.Module):\n    def __init__(self, weights=torch.Tensor([[0.4, 0.55, 0.05]])) -> None:\n        super(DiceLoss, self).__init__()\n        self.eps = 1e-6\n        self.weights = weights\n\n    def forward(\n            self,\n            inputs: torch.Tensor,\n            targets: torch.Tensor) -> torch.Tensor:\n        input_soft = F.softmax(inputs, dim=1)\n\n        target_one_hot = mask2rgb(targets)\n\n        dims = (2, 3)\n        intersection = torch.sum(input_soft * target_one_hot, dims)\n        cardinality = torch.sum(input_soft + target_one_hot, dims)\n\n        dice_score = 2. * intersection / (cardinality + self.eps)\n\n        dice_score = torch.sum(\n            dice_score * self.weights.to(dice_score.device),\n            dim=1\n        )\n        return torch.mean(1. - dice_score)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T11:07:22.995585Z","iopub.execute_input":"2023-11-15T11:07:22.995979Z","iopub.status.idle":"2023-11-15T11:07:23.019613Z","shell.execute_reply.started":"2023-11-15T11:07:22.995951Z","shell.execute_reply":"2023-11-15T11:07:23.017634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#UNET\ndef _make_layers(in_channels: int, out_channels: int):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(inplace=True),\n        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(inplace=True)\n    )\n\n\nclass RecurrentBlock(nn.Module):\n    def __init__(self, ch_out, t=2):\n        super(RecurrentBlock, self).__init__()\n        self.t = t\n        self.ch_out = ch_out\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.BatchNorm2d(ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        for i in range(self.t):\n\n            if i == 0:\n                x1 = self.conv(x)\n\n            x1 = self.conv(x+x1)\n        return x1\n\n\nclass R2Block(nn.Module):\n    def __init__(self, ch_in, ch_out, t=2, max_pool=True):\n        super(R2Block, self).__init__()\n        self.pool = max_pool\n        if max_pool:\n            self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.RCNN = nn.Sequential(\n            RecurrentBlock(ch_out, t=t),\n            RecurrentBlock(ch_out, t=t)\n        )\n        self.Conv_1x1 = nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=1, padding=0)\n\n    def forward(self, x):\n        if self.pool:\n            x = self.max_pool(x)\n        x = self.Conv_1x1(x)\n        x1 = self.RCNN(x)\n        return x+x1\n\n\nclass Attention(nn.Module):\n    def __init__(self, F_g, F_l, F_int):\n        super(Attention, self).__init__()\n        self.W_g = nn.Sequential(\n            nn.Conv2d(F_g, F_int, 1, 1, 0, bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n        self.W_x = nn.Sequential(\n            nn.Conv2d(F_l, F_int, 1, 1, 0, bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n        self.psi = nn.Sequential(\n            nn.Conv2d(F_int, 1, 1, 1, 0, bias=True),\n            nn.BatchNorm2d(1),\n            nn.Sigmoid()\n        )\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, g, x):\n        g1 = self.W_g(g)\n        x1 = self.W_x(x)\n        psi = self.relu(g1+x1)\n        psi = self.psi(psi)\n\n        return x*psi\n\n\nclass DownSample(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.down = nn.Sequential(\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            _make_layers(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.down(x)\n\n\nclass UpSample(nn.Module):\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        attention: bool = False,\n        recurrent: bool = True\n    ):\n        super().__init__()\n        self.attention = attention\n        self.up_conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n        if attention:\n            self.attn = Attention(out_channels, out_channels, out_channels//2)\n        if recurrent:\n            self.conv = R2Block(in_channels, out_channels, max_pool=False)\n        else:\n            self.conv = _make_layers(in_channels, out_channels)\n\n    def forward(self, x1, x2):\n        x1 = self.up_conv(x1)\n        if self.attention:\n            x2 = self.attn(x1, x2)\n        out = torch.cat([x2, x1], dim=1)\n        out = self.conv(out)\n        return out\n\n\nclass UNet(nn.Module):\n    def __init__(\n        self,\n        in_channels: int,\n        attention: bool = True,\n        recurrent: bool = True\n    ):\n        super().__init__()\n        self.attention = attention\n\n        if recurrent:\n            self.conv_in = R2Block(in_channels, 64, max_pool=False)\n            self.down1 = R2Block(64, 128)\n            self.down2 = R2Block(128, 256)\n            self.down3 = R2Block(256, 512)\n            self.down4 = R2Block(512, 1024)\n        else:\n            self.conv_in = _make_layers(in_channels, 64)\n            self.down1 = DownSample(64, 128)\n            self.down2 = DownSample(128, 256)\n            self.down3 = DownSample(256, 512)\n            self.down4 = DownSample(512, 1024)\n\n        self.up1 = UpSample(1024, 512, attention=attention, recurrent=recurrent)\n        self.up2 = UpSample(512, 256, attention=attention, recurrent=recurrent)\n        self.up3 = UpSample(256, 128, attention=attention, recurrent=recurrent)\n        self.up4 = UpSample(128, 64, attention=attention, recurrent=recurrent)\n        self.conv_out = nn.Conv2d(64, 3, kernel_size=1)\n\n    def forward(self, x):\n        x1 = self.conv_in(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x = self.down4(x4)\n        x = self.up1(x, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        x = self.conv_out(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-15T11:07:23.092748Z","iopub.execute_input":"2023-11-15T11:07:23.093061Z","iopub.status.idle":"2023-11-15T11:07:23.128149Z","shell.execute_reply.started":"2023-11-15T11:07:23.093034Z","shell.execute_reply":"2023-11-15T11:07:23.127292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MODEL\n\nclass NeoPolypModel(pl.LightningModule):\n    def __init__(self, lr: float = 1e-4, name: str = \"resunet\"):\n        super().__init__()\n        if name == \"resunet\":\n            self.model = Resnet50Unet(n_classes=3)\n        else:\n            self.model = UNet(in_channels=3)\n        self.lr = lr\n        self.dice_loss = DiceLoss()\n        self.entropy_loss = nn.CrossEntropyLoss()\n\n    def forward(self, x):\n        return self.model(x)\n\n    def _forward(self, batch, batch_idx, name=\"train\"):\n        image, mask = batch['image'].float(), batch['mask'].long()\n        logits = self(image)\n        loss = self.entropy_loss(logits, mask)\n        d_score = dice_score(logits, mask)\n        acc = (logits.argmax(dim=1) == mask).float().mean()\n        self.log_dict(\n            {\n                f\"{name}_loss\": loss,\n                f\"{name}_dice_score\": d_score,\n                f\"{name}_acc\": acc\n            },\n            on_step=False, on_epoch=True, sync_dist=True, prog_bar=True\n        )\n        return loss\n\n    def training_step(self, batch, batch_idx):\n        return self._forward(batch, batch_idx, \"train\")\n\n    def validation_step(self, batch, batch_idx):\n        return self._forward(batch, batch_idx, \"val\")\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(\n            params=self.parameters(),\n            lr=self.lr,\n        )\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer=optimizer,\n            patience=5,\n            verbose=True,\n            factor=0.5\n        )\n        return {\n            'optimizer': optimizer,\n            'lr_scheduler': scheduler,\n            'monitor': 'val_loss',\n            'interval': 'epoch',\n        }","metadata":{"execution":{"iopub.status.busy":"2023-11-15T11:07:23.130497Z","iopub.execute_input":"2023-11-15T11:07:23.130856Z","iopub.status.idle":"2023-11-15T11:07:23.148889Z","shell.execute_reply.started":"2023-11-15T11:07:23.130825Z","shell.execute_reply":"2023-11-15T11:07:23.148028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#RESUNET\n\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU()\n        self.with_nonlinearity = with_nonlinearity\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        if self.with_nonlinearity:\n            x = self.relu(x)\n        return x\n\n\nclass Bridge(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.bridge = nn.Sequential(\n            ConvBlock(in_channels, out_channels),\n            ConvBlock(out_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.bridge(x)\n\n\nclass UpsampleBlock(nn.Module):\n\n    def __init__(self, in_channels, out_channels, up_conv_in_channels=None, up_conv_out_channels=None,\n                 upsampling_method=\"conv_transpose\"):\n        super().__init__()\n\n        if up_conv_in_channels is None:\n            up_conv_in_channels = in_channels\n        if up_conv_out_channels is None:\n            up_conv_out_channels = out_channels\n\n        if upsampling_method == \"conv_transpose\":\n            self.upsample = nn.ConvTranspose2d(up_conv_in_channels, up_conv_out_channels, kernel_size=2, stride=2)\n        elif upsampling_method == \"bilinear\":\n            self.upsample = nn.Sequential(\n                nn.Upsample(mode='bilinear', scale_factor=2),\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n            )\n        self.conv_block_1 = ConvBlock(in_channels, out_channels)\n        self.conv_block_2 = ConvBlock(out_channels, out_channels)\n\n    def forward(self, up_x, down_x):\n        x = self.upsample(up_x)\n        x = torch.cat([x, down_x], 1)\n        x = self.conv_block_1(x)\n        x = self.conv_block_2(x)\n        return x\n\n\nclass Resnet50Unet(nn.Module):\n    DEPTH = 6\n\n    def __init__(self, n_classes=2):\n        super().__init__()\n        resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n        down_blocks = []\n        up_blocks = []\n        self.input_block = nn.Sequential(*list(resnet.children()))[:3]\n        self.input_pool = list(resnet.children())[3]\n        for bottleneck in list(resnet.children()):\n            if isinstance(bottleneck, nn.Sequential):\n                down_blocks.append(bottleneck)\n        self.down_blocks = nn.ModuleList(down_blocks)\n        self.bridge = Bridge(2048, 2048)\n        up_blocks.append(UpsampleBlock(2048, 1024))\n        up_blocks.append(UpsampleBlock(1024, 512))\n        up_blocks.append(UpsampleBlock(512, 256))\n        up_blocks.append(UpsampleBlock(in_channels=128 + 64, out_channels=128,\n                                       up_conv_in_channels=256, up_conv_out_channels=128))\n        up_blocks.append(UpsampleBlock(in_channels=64 + 3, out_channels=64,\n                                       up_conv_in_channels=128, up_conv_out_channels=64))\n\n        self.up_blocks = nn.ModuleList(up_blocks)\n\n        self.out = nn.Conv2d(64, n_classes, kernel_size=1, stride=1)\n\n    def forward(self, x, with_output_feature_map=False):\n        pre_pools = dict()\n        pre_pools[\"layer_0\"] = x\n        x = self.input_block(x)\n        pre_pools[\"layer_1\"] = x\n        x = self.input_pool(x)\n\n        for i, block in enumerate(self.down_blocks, 2):\n            x = block(x)\n            if i == (Resnet50Unet.DEPTH - 1):\n                continue\n            pre_pools[f\"layer_{i}\"] = x\n\n        x = self.bridge(x)\n\n        for i, block in enumerate(self.up_blocks, 1):\n            key = f\"layer_{Resnet50Unet.DEPTH - 1 - i}\"\n            x = block(x, pre_pools[key])\n        output_feature_map = x\n        x = self.out(x)\n        del pre_pools\n        if with_output_feature_map:\n            return x, output_feature_map\n        else:\n            return x","metadata":{"execution":{"iopub.status.busy":"2023-11-15T11:07:23.150434Z","iopub.execute_input":"2023-11-15T11:07:23.150790Z","iopub.status.idle":"2023-11-15T11:07:23.177010Z","shell.execute_reply.started":"2023-11-15T11:07:23.150759Z","shell.execute_reply":"2023-11-15T11:07:23.175711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATALOADER\nimage_path = []\nTRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\nfor root, dirs, files in os.walk(TRAIN_DIR):\n    # iterate over 1000 images\n    for file in files:\n        # create path\n        path = os.path.join(root,file)\n        # add path to list\n        image_path.append(path)\nmask_path = []\nTRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\nfor root, dirs, files in os.walk(TRAIN_MASK_DIR):\n    #iterate over 1000 masks\n    for file in files:\n        # obtain the path\"\n        path = os.path.join(root,file)\n        # add path to the list\n        mask_path.append(path)\nlen(mask_path)\n\nshuffle_list = list(zip(image_path, mask_path))\nrandom.shuffle(shuffle_list)\nimage_path, mask_path = zip(*shuffle_list)\n\ntrain_size = int(0.9 * len(image_path))\ntrain_path = image_path[:train_size]\ntrain_gt_path = mask_path[:train_size]\nval_path = image_path[train_size:]\nval_gt_path = mask_path[train_size:]\ntrain_dataset = NeoPolypDataset(train_path, train_gt_path, session=\"train\")\nval_dataset = NeoPolypDataset(val_path, val_gt_path, session=\"val\")\n\ntrain_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=8,\n    num_workers=4,\n    shuffle=True\n)\n\nval_loader = DataLoader(\n    dataset=val_dataset,\n    batch_size=8,\n    num_workers=4,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T11:07:23.178389Z","iopub.execute_input":"2023-11-15T11:07:23.178902Z","iopub.status.idle":"2023-11-15T11:07:24.606870Z","shell.execute_reply.started":"2023-11-15T11:07:23.178870Z","shell.execute_reply":"2023-11-15T11:07:24.605775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#WANDB\nwandb.login(\n    # set the wandb project where this run will be logged\n#     project= \"PolypSegment\", \n    key = \"c8f1a21c5c6c139ffa2367705a42b34cd76f55b5\",\n)\nwandb.init(\n    project = \"PolypSegment\"\n)\nname = \"unet\"\nlogger = WandbLogger(project=\"PolypSegment\",\n                     name=name,\n                     log_model=\"all\")\n# MODEL\nmodel = NeoPolypModel(lr=0.0001)\n\n# CALLBACK\nroot_path = os.path.join(os.getcwd(), \"checkpoints\")\nckpt_path = os.path.join(os.path.join(root_path, \"model/\"))\nif not os.path.exists(root_path):\n    os.makedirs(root_path)\nif not os.path.exists(ckpt_path):\n    os.makedirs(ckpt_path)\n\nckpt_callback = ModelCheckpoint(\n    monitor=\"val_dice_score\",\n    dirpath=ckpt_path,\n    filename=\"model\",\n    save_top_k=1,\n    mode=\"max\"\n)  # save top 2 epochs with the highest val_dice_score\nlr_callback = LearningRateMonitor(\"step\")\n\nearly_stop_callback = EarlyStopping(\n    monitor=\"val_loss\",\n    patience=15,\n    verbose=True,\n    mode=\"min\"\n)\n\n# TRAINER\ntrainer = pl.Trainer(\n    default_root_dir=root_path,\n    logger=logger,\n    callbacks=[\n        ckpt_callback, lr_callback, early_stop_callback\n    ],\n    gradient_clip_val=1.0,\n    max_epochs=200,\n    enable_progress_bar=True,\n    deterministic=False,\n    accumulate_grad_batches=1\n)\n\n# FIT MODEL\ntrainer.fit(model=model,\n            train_dataloaders=train_loader,\n            val_dataloaders=val_loader)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T11:07:24.609985Z","iopub.execute_input":"2023-11-15T11:07:24.610432Z","iopub.status.idle":"2023-11-15T11:08:24.164963Z","shell.execute_reply.started":"2023-11-15T11:07:24.610391Z","shell.execute_reply":"2023-11-15T11:08:24.161866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mask2rgb(mask):\n    color_dict = {0: torch.tensor([0, 0, 0]),\n                  1: torch.tensor([1, 0, 0]),\n                  2: torch.tensor([0, 1, 0])}\n    output = torch.zeros((mask.shape[0], mask.shape[1], 3)).long()\n    for k in color_dict.keys():\n        output[mask.long() == k] = color_dict[k]\n    return output.to(mask.device)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T11:08:24.167697Z","iopub.execute_input":"2023-11-15T11:08:24.168085Z","iopub.status.idle":"2023-11-15T11:08:24.180586Z","shell.execute_reply.started":"2023-11-15T11:08:24.168038Z","shell.execute_reply":"2023-11-15T11:08:24.179112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = NeoPolypModel.load_from_checkpoint('checkpoints/model/model.ckpt')\nmodel.eval()\ntest_path = []\nTEST_DIR = '/kaggle/input/bkai-igh-neopolyp/test/test/'\nfor root, dirs, files in os.walk(TEST_DIR):\n    for file in files:\n        # create path\n        path = os.path.join(root,file)\n        # add path to list\n        test_path.append(path)\ntest_dataset = NeoPolypDataset(test_path, session=\"test\")\ntest_dataloader = DataLoader(\n    dataset=test_dataset,\n    batch_size=1,\n    num_workers=0,\n    shuffle=False\n)\nif not os.path.isdir('/kaggle/working/predicted_masks'):\n    os.mkdir('/kaggle/working/predicted_masks')\nfor _, (img, file_id, H, W) in enumerate(tqdm(test_dataloader, total=len(test_dataloader))):\n    with torch.no_grad():\n        predicted_mask = model(img.cuda())\n    for i in range(1):\n        filename = file_id[i] + \".png\"\n        argmax = torch.argmax(predicted_mask[i], 0)\n        one_hot = mask2rgb(argmax).float().permute(2, 0, 1)\n        mask2img = Resize((H[i].item(), W[i].item()), interpolation=InterpolationMode.NEAREST)(\n            ToPILImage()(one_hot))\n        mask2img.save(os.path.join('/kaggle/working/predicted_masks', filename))","metadata":{"execution":{"iopub.status.busy":"2023-11-15T11:08:24.182448Z","iopub.execute_input":"2023-11-15T11:08:24.182901Z","iopub.status.idle":"2023-11-15T11:08:25.491753Z","shell.execute_reply.started":"2023-11-15T11:08:24.182866Z","shell.execute_reply":"2023-11-15T11:08:25.490014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 0] = 255\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    \n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    return rle_to_string(rle)\n\ndef mask2string(dir):\n    ## mask --> string\n    strings = []\n    ids = []\n    ws, hs = [[] for i in range(2)]\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n        print(path)\n        img = cv2.imread(path)[:,:,::-1]\n        h, w = img.shape[0], img.shape[1]\n        for channel in range(2):\n            ws.append(w)\n            hs.append(h)\n            ids.append(f'{id}_{channel}')\n            string = rle_encode_one_mask(img[:,:,channel])\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r\n\n\nMASK_DIR_PATH = '/kaggle/working/predicted_masks' # change this to the path to your output mask folder\ndir = MASK_DIR_PATH\nres = mask2string(dir)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\ndf.to_csv(r'output.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T11:08:25.492859Z","iopub.status.idle":"2023-11-15T11:08:25.493341Z","shell.execute_reply.started":"2023-11-15T11:08:25.493098Z","shell.execute_reply":"2023-11-15T11:08:25.493120Z"},"trusted":true},"execution_count":null,"outputs":[]}]}